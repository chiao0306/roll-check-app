import streamlit as st
from azure.core.credentials import AzureKeyCredential
from azure.ai.documentintelligence import DocumentIntelligenceClient
from azure.ai.documentintelligence.models import AnalyzeResult
import google.generativeai as genai
import json

# --- 1. é é¢è¨­å®š ---
st.set_page_config(page_title="ä¸­é‹¼æ©Ÿæ¢°ç¨½æ ¸", page_icon="ğŸ­", layout="centered")

# --- 2. ç§˜å¯†é‡‘é‘°è®€å– ---
try:
    DOC_ENDPOINT = st.secrets["DOC_ENDPOINT"]
    DOC_KEY = st.secrets["DOC_KEY"]
    GEMINI_KEY = st.secrets["GEMINI_KEY"]
except:
    st.error("æ‰¾ä¸åˆ°é‡‘é‘°ï¼è«‹åœ¨ Streamlit Cloud è¨­å®š Secretsã€‚")
    st.stop()

# --- 3. åˆå§‹åŒ– Session State ---
if 'photo_gallery' not in st.session_state:
    st.session_state.photo_gallery = []
if 'uploader_key' not in st.session_state:
    st.session_state.uploader_key = 0

# --- 4. æ ¸å¿ƒå‡½æ•¸ï¼šAzure ç¥ä¹‹çœ¼ ---
def extract_layout_with_azure(file_obj, endpoint, key):
    client = DocumentIntelligenceClient(endpoint=endpoint, credential=AzureKeyCredential(key))
    file_content = file_obj.getvalue()
    
    # å‘¼å« Azure
    poller = client.begin_analyze_document(
        "prebuilt-layout", 
        file_content,
        content_type="application/octet-stream"
    )
    result: AnalyzeResult = poller.result()
    
    markdown_output = ""
    # A. æå–è¡¨æ ¼
    if result.tables:
        for idx, table in enumerate(result.tables):
            page_num = "Unknown"
            if table.bounding_regions: page_num = table.bounding_regions[0].page_number
            markdown_output += f"\n### Table {idx + 1} (Page {page_num}):\n"
            rows = {}
            for cell in table.cells:
                r, c = cell.row_index, cell.column_index
                content = cell.content.replace("\n", " ").strip()
                if r not in rows: rows[r] = {}
                rows[r][c] = content
            for r in sorted(rows.keys()):
                row_cells = []
                if rows[r]:
                    max_col = max(rows[r].keys())
                    for c in range(max_col + 1): row_cells.append(rows[r].get(c, ""))
                    markdown_output += "| " + " | ".join(row_cells) + " |\n"
    
    # B. æå–è¡¨é ­ (å‰ 300 å­—)
    header_snippet = result.content[:300] if result.content else ""
    
    # C. æå–é å°¾/ç°½æ ¸å€ (å¾Œ 300 å­—) - æ–°å¢
    footer_snippet = result.content[-300:] if result.content and len(result.content) > 300 else ""
    
    # å›å‚³çµæ§‹åŒ…å«é å°¾ï¼Œä¾›ç°½æ ¸æ—¥æœŸæª¢æŸ¥
    return markdown_output, f"--- Header ---\n{header_snippet}\n--- Footer ---\n{footer_snippet}"

# --- 5. æ ¸å¿ƒå‡½æ•¸ï¼šGemini ç¥ä¹‹è…¦ (æ—¥æœŸæ ¸å°å‡ç´š) ---
def audit_with_gemini(extracted_data_list, api_key):
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel("models/gemini-2.5-pro")
    
    combined_input = "ä»¥ä¸‹æ˜¯å„é è³‡æ–™ï¼š\n"
    for data in extracted_data_list:
        combined_input += f"\n=== Page {data['page']} ===\n"
        combined_input += f"{data['text_snippets']}\n"
        combined_input += f"ã€è¡¨æ ¼æ•¸æ“šã€‘:\n{data['table']}\n"

    system_prompt = """
    ä½ æ˜¯ä¸€ä½æ¥µåº¦åš´è¬¹çš„ä¸­é‹¼æ©Ÿæ¢°å“ç®¡ç¨½æ ¸å“¡ã€‚
    è«‹ä¾æ“š Azure OCR æå–çš„è¡¨æ ¼æ–‡å­—é€²è¡Œç¨½æ ¸ã€‚

    ### 0. æ ¸å¿ƒä»»å‹™èˆ‡æ•¸æ“šæ¸…æ´—ï¼š
    - **è­˜åˆ¥æ»¾è¼ªç·¨è™Ÿ (Roll ID)**ï¼šæ‰¾å‡ºæ¯ç­†æ•¸æ“šå°æ‡‰çš„ç·¨è™Ÿ (å¦‚ `Y5612001`)ã€‚
    - **é ç¢¼è¿½è¹¤ (Page Tracking)**ï¼šè‹¥ç•°å¸¸æ¶‰åŠè·¨é æµç¨‹ï¼Œè«‹åœ¨ `page` æ¬„ä½åˆ—å‡ºæ‰€æœ‰ç›¸é—œé ç¢¼ (å¦‚ "1, 2")ã€‚
    - **æ•¸å€¼å®¹éŒ¯**ï¼šé‡åˆ°æ•¸å­—é–“æœ‰ç©ºæ ¼ (å¦‚ `341 . 12`)ï¼Œè«‹å¿½ç•¥ç©ºæ ¼è¦–ç‚ºæ­£å¸¸æ•¸å€¼ `341.12`ã€‚

    ### 1. è·¨é ä¸€è‡´æ€§èˆ‡æ—¥æœŸæ ¸å° (Header & Signature)ï¼š
    - **è¡¨é ­æª¢æŸ¥**ï¼š
      - å·¥ä»¤ç·¨è™Ÿã€é å®šäº¤è²¨æ—¥æœŸã€å¯¦éš›äº¤è²¨æ—¥æœŸï¼šæ‰€æœ‰é é¢å¿…é ˆç›¸åŒã€‚
      - æ—¥æœŸæ ¼å¼ï¼š`YYY.MM.DD` (å…è¨±ç©ºæ ¼)ã€‚
    - **ç°½æ ¸æ—¥æœŸæ ¸å° (Signature Date Sync)** - ã€æ–°å¢ã€‘ï¼š
      - è«‹æª¢æŸ¥é å°¾æˆ–ç°½æ ¸æ¬„ä½æ˜¯å¦æœ‰å¡«å¯«æ—¥æœŸã€‚
      - **è¦å‰‡**ï¼šè‹¥æœ‰ç°½æ ¸æ—¥æœŸï¼Œè©²æ—¥æœŸå¿…é ˆèˆ‡è¡¨é ­çš„ **ã€Œå¯¦éš›äº¤è²¨æ—¥æœŸã€** å®Œå…¨ä¸€è‡´ã€‚
      - **å®¹éŒ¯**ï¼š`114.10.22` èˆ‡ `114å¹´10æœˆ22æ—¥` è¦–ç‚ºç›¸åŒã€‚
      - **ç•°å¸¸**ï¼šè‹¥æ—¥æœŸä¸ç¬¦æˆ–æ—¥æœŸç„¡æ•ˆ (å¦‚ `0æœˆ`) -> **FAIL**ã€‚
      - (è‹¥ç°½æ ¸æ¬„ç©ºç™½å‰‡å¿½ç•¥ï¼Œä¸éœ€æª¢æŸ¥)ã€‚

    ### 2. è£½ç¨‹åˆ¤å®šé‚è¼¯ (åˆ†è»Œåˆ¶)ï¼š

    #### A. ã€æœ¬é«” (Body)ã€‘æœªå†ç”Ÿ/è»Šä¿®ï¼š
    - **è¦æ ¼è§£æ**ï¼šå¿½ç•¥ã€Œæ¯æ¬¡è»Šä¿®Xmmã€ï¼Œåªçœ‹ã€Œè‡³ Ymmã€ã€‚å–æœ€å¤§å€¼ç‚º Max_Specã€‚
    - **é‚è¼¯åˆ†æµ**ï¼š
      1. **å¯¦æ¸¬å€¼ç‚ºã€Œæ•´æ•¸ã€** (æœªå®Œå·¥)ï¼š
         - è¦å‰‡ï¼šå¯¦æ¸¬å€¼ **<=** è¦æ ¼å€¼ã€‚
      2. **å¯¦æ¸¬å€¼æœ‰ã€Œå°æ•¸é»ã€** (å·²å®Œå·¥)ï¼š
         - è¦å‰‡ï¼šå¯¦æ¸¬å€¼ **>=** è¦æ ¼å€¼ã€‚
         - æ ¼å¼ï¼šå¿½ç•¥ç©ºæ ¼å¾Œï¼Œå¿…é ˆç²¾ç¢ºåˆ°å°æ•¸é»å¾Œå…©ä½ (`#.##`)ã€‚
         - **æ¨™è¨˜**ï¼šæ­¤ç·¨è™Ÿç‹€æ…‹ç‚ºã€Œæœ¬é«”å·²å®Œå·¥ã€ã€‚

    #### B. ã€è»¸é ¸ (Journal)ã€‘æœªå†ç”Ÿ/è»Šä¿®ï¼š
    - **é‚è¼¯**ï¼š
       - è¦æ ¼æ¯”å°ï¼šæ™ºæ…§æ­¸é¡ã€‚
       - **å¼·åˆ¶è¦å‰‡**ï¼šå¯¦æ¸¬å€¼å¿…é ˆç‚º **æ•´æ•¸**ã€‚
       - è‹¥å‡ºç¾å°æ•¸é» -> **FAIL** (è»¸é ¸æœªå†ç”Ÿä¸å¯å®Œå·¥)ã€‚

    #### C. éŠ²è£œ (Welding) (é€šç”¨)ï¼š
    - è¦å‰‡ï¼šå¯¦æ¸¬å€¼ **>=** è¦æ ¼ã€‚

    #### D. å†ç”Ÿè»Šä¿® (Finish) (é€šç”¨)ï¼š
    - æ•¸å€¼ï¼š**åŒ…å«æ–¼ (Inclusive)** ä¸Šä¸‹é™ä¹‹é–“ã€‚
    - æ ¼å¼ï¼šå¿½ç•¥ç©ºæ ¼å¾Œï¼Œå¿…é ˆç²¾ç¢ºåˆ°å°æ•¸é»å¾Œå…©ä½ã€‚

    ### 3. å…¨åŸŸæµç¨‹é˜²å‘† (Global Process Integrity)ï¼š
    - **å‰å‘æª¢æŸ¥**ï¼šè‹¥æŸç·¨è™Ÿåœ¨ã€Œæœ¬é«”æœªå†ç”Ÿã€å·²æ¨™è¨˜ç‚ºã€Œå·²å®Œå·¥ã€(æœ‰å°æ•¸é»)ï¼Œå‰‡ **ä¸å¯å‡ºç¾** åœ¨ã€Œæœ¬é«”éŠ²è£œã€æˆ–ã€Œæœ¬é«”å†ç”Ÿè»Šä¿®ã€ã€‚
    - **å¾Œå‘æª¢æŸ¥**ï¼šè‹¥æŸç·¨è™Ÿå‡ºç¾åœ¨ã€ŒéŠ²è£œã€æˆ–ã€Œå†ç”Ÿè»Šä¿®ã€ï¼Œå‰‡ **å¿…é ˆå‡ºç¾** åœ¨è©²éƒ¨ä½çš„ã€Œæœªå†ç”Ÿã€éšæ®µã€‚
    - **å°ºå¯¸åˆç†æ€§**ï¼šæª¢æŸ¥åŒä¸€ç·¨è™Ÿåœ¨å„éšæ®µå°ºå¯¸æ˜¯å¦åŠ‡çƒˆè·³å‹• (å¦‚ 350 -> 200 -> FAIL)ã€‚

    ### 4. æ•¸é‡ä¸€è‡´æ€§æª¢æŸ¥ï¼š
    - è®€å– `(10PC)` -> æ¸…é»å¯¦æ¸¬å€‹æ•¸ã€‚
    - è‹¥ `å¯¦æ¸¬å€‹æ•¸ â‰  è¦æ±‚å€‹æ•¸` -> **FAIL (æ•¸é‡ä¸ç¬¦)**ã€‚
    - ä¾‹å¤–ï¼šã€Œç†±è™•ç†ã€å¿½ç•¥æ•¸é‡ã€‚

    ### è¼¸å‡ºæ ¼å¼ (JSON Only)ï¼š
    {
      "job_no": "å·¥ä»¤ç·¨è™Ÿ",
      "summary": "ç¸½çµ",
      "issues": [
         {
           "page": "é ç¢¼ (å­—ä¸²ï¼Œå¦‚ '1' æˆ– '1, 3')",
           "item": "é …ç›®åç¨±",
           "issue_type": "æ•¸å€¼è¶…è¦ / æ•¸é‡ä¸ç¬¦ / æµç¨‹ç•°å¸¸ / å°ºå¯¸ç•°å¸¸ / æ ¼å¼éŒ¯èª¤ / æ—¥æœŸä¸ç¬¦",
           "spec_logic": "åˆ¤å®šæ¨™æº–",
           "common_reason": "éŒ¯èª¤åŸå› æ¦‚è¿°",
           "failures": [
              {"id": "Y5612001", "val": "136"}
           ]
         }
      ]
    }
    """
    
    try:
        response = model.generate_content(
            [system_prompt, combined_input],
            generation_config={"response_mime_type": "application/json"}
        )
        return response.text
    except Exception as e:
        return f"Error: {str(e)}"

# --- 6. æ‰‹æ©Ÿç‰ˆ UI ---
st.title("ğŸ­ ç¾å ´ç¨½æ ¸åŠ©æ‰‹")

# A. æª”æ¡ˆä¸Šå‚³å€
with st.container(border=True):
    st.subheader("ğŸ“‚ æ–°å¢é é¢")
    uploaded_files = st.file_uploader(
        "é»æ“Šä¸Šå‚³ (æ‰‹æ©Ÿå¯é¸ç›´æ¥æ‹ç…§)", 
        type=['jpg', 'png', 'jpeg'], 
        accept_multiple_files=True,
        key=f"uploader_{st.session_state.uploader_key}"
    )
    if uploaded_files:
        for f in uploaded_files:
            st.session_state.photo_gallery.append(f)
        st.session_state.uploader_key += 1
        st.rerun()

# B. é è¦½èˆ‡ç®¡ç†å€
if st.session_state.photo_gallery:
    st.divider()
    st.write(f"ğŸ“Š å·²ç´¯ç© **{len(st.session_state.photo_gallery)}** é æ–‡ä»¶")
    
    cols = st.columns(3)
    for idx, img in enumerate(st.session_state.photo_gallery):
        with cols[idx % 3]:
            st.image(img, caption=f"P.{idx+1}", use_container_width=True)
            if st.button("âŒ", key=f"del_{idx}"):
                st.session_state.photo_gallery.pop(idx)
                st.rerun()

    # C. åŸ·è¡ŒæŒ‰éˆ•
    st.divider()
    
    if st.button("ğŸš€ é–‹å§‹åˆ†æ (æ—¥æœŸæ ¸å°ç‰ˆ)", type="primary", use_container_width=True):
        
        status = st.empty()
        progress_bar = st.progress(0)
        
        # 1. OCR
        extracted_data_list = []
        total_imgs = len(st.session_state.photo_gallery)
        
        for i, img in enumerate(st.session_state.photo_gallery):
            status.text(f"Azure æ­£åœ¨æƒæç¬¬ {i+1}/{total_imgs} é ...")
            img.seek(0)
            try:
                table_md, text_snippets = extract_layout_with_azure(img, DOC_ENDPOINT, DOC_KEY)
                extracted_data_list.append({
                    "page": i + 1,
                    "table": table_md,
                    "text_snippets": text_snippets 
                })
            except Exception as e:
                st.error(f"ç¬¬ {i+1} é è®€å–å¤±æ•—: {e}")
            progress_bar.progress((i + 1) / (total_imgs + 1))

        # 2. Gemini
        status.text(f"Gemini 2.5 Pro æ­£åœ¨é€²è¡Œé‚è¼¯èˆ‡æ—¥æœŸæ ¸å°...")
        result_str = audit_with_gemini(extracted_data_list, GEMINI_KEY)
        
        progress_bar.progress(100)
        status.text("å®Œæˆï¼")

        # 3. é¡¯ç¤ºçµæœ
        try:
            result = json.loads(result_str)
            if isinstance(result, list): result = result[0] if len(result) > 0 else {}
            
            st.success(f"å·¥ä»¤: {result.get('job_no', 'Unknown')}")
            
            issues = result.get('issues', [])
            if not issues:
                st.balloons()
                st.success("âœ… å…¨æ•¸åˆæ ¼ï¼")
            else:
                st.error(f"ç™¼ç¾ {len(issues)} é¡ç•°å¸¸é …ç›®")
                
                for item in issues:
                    with st.container(border=True):
                        # æ¨™é¡Œ
                        col_head1, col_head2 = st.columns([3, 1])
                        
                        # æ¨™é¡Œé¡¯ç¤ºï¼š[é ç¢¼] é …ç›®
                        page_str = str(item.get('page', '?'))
                        col_head1.markdown(f"**P.{page_str} | {item.get('item')}**")
                        
                        itype = item.get('issue_type', 'ç•°å¸¸')
                        if "æµç¨‹" in itype or "å°ºå¯¸" in itype or "æ—¥æœŸ" in itype:
                            col_head2.error(f"ğŸ›‘ {itype}")
                        else:
                            col_head2.warning(f"âš ï¸ {itype}")
                        
                        st.caption(f"åŸå› : {item.get('common_reason')}")
                        if item.get('spec_logic'):
                            st.caption(f"æ¨™æº–: {item.get('spec_logic')}")
                        
                        # æ˜ç´°è¡¨æ ¼
                        failures = item.get('failures', [])
                        if failures:
                            table_data = [{"æ»¾è¼ªç·¨è™Ÿ": f.get('id', 'æœªçŸ¥'), "å¯¦æ¸¬å€¼": f.get('val', 'N/A')} for f in failures]
                            st.dataframe(table_data, use_container_width=True, hide_index=True)
                        else:
                             st.text(f"å¯¦æ¸¬æ•¸æ“š: {item.get('measured', 'N/A')}")
                            
        except Exception as e:
            st.error("åˆ†æéŒ¯èª¤")
            st.code(result_str)
            st.write(e)
            
    if st.button("ğŸ—‘ï¸ æ¸…é™¤æ‰€æœ‰ç…§ç‰‡"):
        st.session_state.photo_gallery = []
        st.rerun()

else:
    st.info("ğŸ‘† è«‹é»æ“Šä¸Šæ–¹æŒ‰éˆ•é–‹å§‹æ–°å¢ç…§ç‰‡")
